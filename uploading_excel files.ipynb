{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bacfb43b-9b6d-44c2-af17-9ef164bcfd5e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ ÿ™ŸÖ ÿßŸÑÿßÿ™ÿµÿßŸÑ ÿ®ŸÄ Azure SQL ÿ®ŸÜÿ¨ÿßÿ≠!\n",
      "\n",
      "üìò Processing file: olist_closed_deals_dataset.xlsx\n",
      "   ‚¨ÜÔ∏è Uploading sheet 'olist_closed_deals_dataset' ‚Üí table 'olist_closed_deals_dataset_olist_closed_deals_dataset' ...\n",
      "   ‚úÖ Uploaded successfully!\n",
      "\n",
      "üìò Processing file: olist_marketing_qualified_leads_dataset.xlsx\n",
      "   ‚¨ÜÔ∏è Uploading sheet 'olist_marketing_qualified_leads' ‚Üí table 'olist_marketing_qualified_leads_dataset_olist_marketing_qualified_leads' ...\n",
      "   ‚úÖ Uploaded successfully!\n",
      "\n",
      "üéâ All Excel files processed successfully!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "import urllib\n",
    "\n",
    "# --- ‚öôÔ∏è SETTINGS ---\n",
    "# Folder containing your Excel files\n",
    "excel_folder = r\"D:\\Data\\Markting_olist\"   # e.g. folder with multiple .xlsx files\n",
    "\n",
    "# ÿ®ŸäÿßŸÜÿßÿ™ ÿßŸÑÿßÿ™ÿµÿßŸÑ\n",
    "server = \"almagraby.database.windows.net\"\n",
    "database = \"Olist_dataset\"\n",
    "username = \"DEPI_Projecte\"\n",
    "password = \"Almaghraby@240https://api.cognitive.microsofttranslator.com\"\n",
    "driver = \"ODBC Driver 18 for SQL Server\"\n",
    "\n",
    "# ÿ™ÿ±ŸÖŸäÿ≤ ŸÉŸÑŸÖÿ© ÿßŸÑŸÖÿ±Ÿàÿ± ŸÑÿ™ŸÅÿßÿØŸä ŸÖÿ¥ÿßŸÉŸÑ ÿßŸÑÿ±ŸÖŸàÿ≤ ÿßŸÑÿÆÿßÿµÿ© ŸÖÿ´ŸÑ @\n",
    "encoded_password = urllib.parse.quote_plus(password)\n",
    "\n",
    "# ÿ®ŸÜÿßÿ° ÿßŸÑÿßÿ™ÿµÿßŸÑ ÿ®ÿ¥ŸÉŸÑ ÿ¢ŸÖŸÜ\n",
    "conn_str = (\n",
    "    f\"mssql+pyodbc://{username}:{encoded_password}@{server}:1433/{database}\"\n",
    "    f\"?driver={driver}&Encrypt=yes&TrustServerCertificate=no\"\n",
    ")\n",
    "\n",
    "# ÿßÿÆÿ™ÿ®ÿßÿ± ÿßŸÑÿßÿ™ÿµÿßŸÑ\n",
    "engine = create_engine(conn_str)\n",
    "\n",
    "try:\n",
    "    with engine.connect() as conn:\n",
    "        print(\"‚úÖ ÿ™ŸÖ ÿßŸÑÿßÿ™ÿµÿßŸÑ ÿ®ŸÄ Azure SQL ÿ®ŸÜÿ¨ÿßÿ≠!\")\n",
    "except Exception as e:\n",
    "    print(\"‚ùå ŸÅÿ¥ŸÑ ÿßŸÑÿßÿ™ÿµÿßŸÑ:\", e)\n",
    "\n",
    "# --- üìÇ Loop through all Excel files in the folder ---\n",
    "for file_name in os.listdir(excel_folder):\n",
    "    if file_name.endswith(\".xlsx\"):\n",
    "        file_path = os.path.join(excel_folder, file_name)\n",
    "        print(f\"\\nüìò Processing file: {file_name}\")\n",
    "\n",
    "        # Read all sheets in workbook\n",
    "        sheets = pd.read_excel(file_path, sheet_name=None)\n",
    "\n",
    "        # Upload each sheet as a table\n",
    "        for sheet_name, df in sheets.items():\n",
    "            # Clean table name: file name + sheet name\n",
    "            base_name = os.path.splitext(file_name)[0].replace(\" \", \"_\")\n",
    "            clean_sheet = sheet_name.replace(\" \", \"_\")\n",
    "            table_name = f\"{base_name}_{clean_sheet}\"\n",
    "\n",
    "            print(f\"   ‚¨ÜÔ∏è Uploading sheet '{sheet_name}' ‚Üí table '{table_name}' ...\")\n",
    "            try:\n",
    "                df.to_sql(table_name, con=engine, if_exists=\"replace\", index=False)\n",
    "                print(f\"   ‚úÖ Uploaded successfully!\")\n",
    "            except Exception as e:\n",
    "                print(f\"   ‚ùå Failed to upload '{sheet_name}' from '{file_name}': {e}\")\n",
    "\n",
    "print(\"\\nüéâ All Excel files processed successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "823420cb-4a9d-44db-b535-fe7b14addad2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ ÿ™ŸÖ ÿßŸÑÿßÿ™ÿµÿßŸÑ ÿ®ŸÄ Azure SQL ÿ®ŸÜÿ¨ÿßÿ≠!\n"
     ]
    }
   ],
   "source": [
    "import urllib\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# ÿ®ŸäÿßŸÜÿßÿ™ ÿßŸÑÿßÿ™ÿµÿßŸÑ\n",
    "server = \"almagraby.database.windows.net\"\n",
    "database = \"Olist_dataset\"\n",
    "username = \"DEPI_Projecte\"\n",
    "password = \"Almaghraby@240\"\n",
    "driver = \"ODBC Driver 18 for SQL Server\"\n",
    "\n",
    "# ÿ™ÿ±ŸÖŸäÿ≤ ŸÉŸÑŸÖÿ© ÿßŸÑŸÖÿ±Ÿàÿ± ŸÑÿ™ŸÅÿßÿØŸä ŸÖÿ¥ÿßŸÉŸÑ ÿßŸÑÿ±ŸÖŸàÿ≤ ÿßŸÑÿÆÿßÿµÿ© ŸÖÿ´ŸÑ @\n",
    "encoded_password = urllib.parse.quote_plus(password)\n",
    "\n",
    "# ÿ®ŸÜÿßÿ° ÿßŸÑÿßÿ™ÿµÿßŸÑ ÿ®ÿ¥ŸÉŸÑ ÿ¢ŸÖŸÜ\n",
    "conn_str = (\n",
    "    f\"mssql+pyodbc://{username}:{encoded_password}@{server}:1433/{database}\"\n",
    "    f\"?driver={driver}&Encrypt=yes&TrustServerCertificate=no\"\n",
    ")\n",
    "\n",
    "# ÿßÿÆÿ™ÿ®ÿßÿ± ÿßŸÑÿßÿ™ÿµÿßŸÑ\n",
    "engine = create_engine(conn_str)\n",
    "\n",
    "try:\n",
    "    with engine.connect() as conn:\n",
    "        print(\"‚úÖ ÿ™ŸÖ ÿßŸÑÿßÿ™ÿµÿßŸÑ ÿ®ŸÄ Azure SQL ÿ®ŸÜÿ¨ÿßÿ≠!\")\n",
    "except Exception as e:\n",
    "    print(\"‚ùå ŸÅÿ¥ŸÑ ÿßŸÑÿßÿ™ÿµÿßŸÑ:\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4e5d562d-d6bf-46ab-872e-1f8bafd7a5f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "import urllib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "07f3ce31-7909-4db3-a9bb-83a5db0e9447",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pymssql'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpymssql\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mrequests\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01muuid\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pymssql'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pymssql\n",
    "import requests\n",
    "import uuid\n",
    "import time\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "# Azure SQL Server Configuration\n",
    "SERVER = 'almagraby.database.windows.net'\n",
    "DATABASE = 'Olist_dataset'\n",
    "USERNAME = 'DEPI_Projecte'\n",
    "PASSWORD = 'Almaghraby@240'\n",
    "TABLE_NAME = 'olist_geolocation_dataset_olist_geolocation_dataset'  # Table containing geolocation_city column\n",
    "\n",
    "# Azure Translator Configuration\n",
    "AZURE_TRANSLATOR_KEY = 'AunHlUi5xLkxOBfcQnwIYmiLxh2PztKTD5b5Kbfu4uiLHt1alQKdJQQJ99BJACF24PCXJ3w3AAAbACOGZEWL'  # From Azure Portal\n",
    "AZURE_TRANSLATOR_REGION = 'uaenorth'  # Your translator region (e.g., eastus, westeurope)\n",
    "AZURE_TRANSLATOR_ENDPOINT = 'https://almagraby.cognitiveservices.azure.com/'\n",
    "\n",
    "# Performance Settings\n",
    "BATCH_SIZE = 100\n",
    "MAX_WORKERS = 5\n",
    "DB_UPDATE_BATCH_SIZE = 50  # CRITICAL: Smaller batches for UPDATE statements\n",
    "\n",
    "def get_connection():\n",
    "    \"\"\"Create a new database connection with retry logic\"\"\"\n",
    "    max_retries = 3\n",
    "    retry_delay = 5\n",
    "    \n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            conn = pymssql.connect(\n",
    "                server=SERVER,\n",
    "                user=USERNAME,\n",
    "                password=PASSWORD,\n",
    "                database=DATABASE,\n",
    "                port=1433,\n",
    "                tds_version='7.4',\n",
    "                timeout=60,\n",
    "                login_timeout=60\n",
    "            )\n",
    "            return conn\n",
    "        except pymssql.OperationalError as e:\n",
    "            error_code = e.args[0] if e.args else None\n",
    "            \n",
    "            if error_code == 40615:\n",
    "                # Firewall blocking\n",
    "                print(f\"\\n‚ö†Ô∏è  FIREWALL ERROR (Attempt {attempt + 1}/{max_retries})\")\n",
    "                print(\"=\" * 70)\n",
    "                print(\"Your Azure SQL Server firewall is blocking this connection.\")\n",
    "                print(\"\\nTO FIX THIS:\")\n",
    "                print(\"1. Get your current IP:\")\n",
    "                \n",
    "                try:\n",
    "                    import requests\n",
    "                    current_ip = requests.get('https://api.ipify.org', timeout=5).text\n",
    "                    print(f\"   Your IP: {current_ip}\")\n",
    "                except:\n",
    "                    print(\"   Run: import requests; print(requests.get('https://api.ipify.org').text)\")\n",
    "                \n",
    "                print(\"\\n2. Add to Azure Firewall:\")\n",
    "                print(\"   ‚Ä¢ Azure Portal ‚Üí SQL Server ‚Üí Networking\")\n",
    "                print(\"   ‚Ä¢ Click '+ Add firewall rule'\")\n",
    "                print(f\"   ‚Ä¢ Start IP: {current_ip if 'current_ip' in locals() else '<your_ip>'}\")\n",
    "                print(f\"   ‚Ä¢ End IP: {current_ip if 'current_ip' in locals() else '<your_ip>'}\")\n",
    "                print(\"   ‚Ä¢ Click 'Save' and wait 2-5 minutes\")\n",
    "                print(\"\\n3. OR Enable 'Allow Azure services' (Recommended):\")\n",
    "                print(\"   ‚Ä¢ Azure Portal ‚Üí SQL Server ‚Üí Networking\")\n",
    "                print(\"   ‚Ä¢ Toggle ON: 'Allow Azure services and resources to access this server'\")\n",
    "                print(\"   ‚Ä¢ Click 'Save'\")\n",
    "                print(\"=\" * 70)\n",
    "                \n",
    "                if attempt < max_retries - 1:\n",
    "                    print(f\"\\nWaiting {retry_delay} seconds before retry...\")\n",
    "                    time.sleep(retry_delay)\n",
    "                else:\n",
    "                    print(\"\\n‚ùå Max retries reached. Please fix firewall and re-run.\")\n",
    "                    raise\n",
    "            else:\n",
    "                # Other connection errors\n",
    "                print(f\"\\n‚ùå Connection Error: {e}\")\n",
    "                if attempt < max_retries - 1:\n",
    "                    print(f\"Retrying in {retry_delay} seconds...\")\n",
    "                    time.sleep(retry_delay)\n",
    "                else:\n",
    "                    raise\n",
    "        except Exception as e:\n",
    "            print(f\"\\n‚ùå Unexpected Error: {e}\")\n",
    "            if attempt < max_retries - 1:\n",
    "                print(f\"Retrying in {retry_delay} seconds...\")\n",
    "                time.sleep(retry_delay)\n",
    "            else:\n",
    "                raise\n",
    "    \n",
    "    raise Exception(\"Failed to connect after all retries\")\n",
    "\n",
    "def translate_batch_azure(cities):\n",
    "    \"\"\"Translate a batch of cities using Azure Translator API\"\"\"\n",
    "    if not cities:\n",
    "        return {}\n",
    "    \n",
    "    valid_cities = [city for city in cities if pd.notna(city) and city != '']\n",
    "    \n",
    "    if not valid_cities:\n",
    "        return {city: city for city in cities}\n",
    "    \n",
    "    path = '/translate'\n",
    "    constructed_url = AZURE_TRANSLATOR_ENDPOINT + path\n",
    "    \n",
    "    params = {\n",
    "        'api-version': '3.0',\n",
    "        'from': 'auto',\n",
    "        'to': 'en'\n",
    "    }\n",
    "    \n",
    "    headers = {\n",
    "        'Ocp-Apim-Subscription-Key': AZURE_TRANSLATOR_KEY,\n",
    "        'Ocp-Apim-Subscription-Region': AZURE_TRANSLATOR_REGION,\n",
    "        'Content-type': 'application/json',\n",
    "        'X-ClientTraceId': str(uuid.uuid4())\n",
    "    }\n",
    "    \n",
    "    body = [{'text': str(city)} for city in valid_cities]\n",
    "    translations = {}\n",
    "    \n",
    "    try:\n",
    "        response = requests.post(constructed_url, params=params, headers=headers, json=body)\n",
    "        response.raise_for_status()\n",
    "        results = response.json()\n",
    "        \n",
    "        for city, result in zip(valid_cities, results):\n",
    "            translated_text = result['translations'][0]['text']\n",
    "            translations[city] = translated_text\n",
    "        \n",
    "        for city in cities:\n",
    "            if pd.isna(city) or city == '':\n",
    "                translations[city] = city\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Translation error: {e}\")\n",
    "        translations = {city: city for city in cities}\n",
    "    \n",
    "    return translations\n",
    "\n",
    "def translate_all_cities(unique_cities, batch_size=BATCH_SIZE, max_workers=MAX_WORKERS):\n",
    "    \"\"\"Translate all unique cities using Azure Translator with parallel processing\"\"\"\n",
    "    print(f\"Translating {len(unique_cities)} unique cities...\")\n",
    "    \n",
    "    city_batches = [unique_cities[i:i + batch_size] \n",
    "                    for i in range(0, len(unique_cities), batch_size)]\n",
    "    \n",
    "    all_translations = {}\n",
    "    completed = 0\n",
    "    \n",
    "    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        future_to_batch = {executor.submit(translate_batch_azure, batch): batch \n",
    "                          for batch in city_batches}\n",
    "        \n",
    "        for future in as_completed(future_to_batch):\n",
    "            try:\n",
    "                translations = future.result()\n",
    "                all_translations.update(translations)\n",
    "                completed += len(translations)\n",
    "                progress = (completed * 100) // len(unique_cities)\n",
    "                print(f\"Progress: {completed}/{len(unique_cities)} cities ({progress}%)\")\n",
    "            except Exception as e:\n",
    "                print(f\"Batch processing error: {e}\")\n",
    "    \n",
    "    return all_translations\n",
    "\n",
    "def update_database_small_batches(translations, table_name, batch_size=DB_UPDATE_BATCH_SIZE):\n",
    "    \"\"\"\n",
    "    Update database in SMALL batches to avoid query size limits\n",
    "    Uses individual UPDATE statements, not CASE\n",
    "    \"\"\"\n",
    "    if not translations:\n",
    "        return\n",
    "    \n",
    "    valid_translations = {k: v for k, v in translations.items() \n",
    "                         if k and v and pd.notna(k) and pd.notna(v)}\n",
    "    \n",
    "    if not valid_translations:\n",
    "        print(\"No valid translations to update\")\n",
    "        return\n",
    "    \n",
    "    total = len(valid_translations)\n",
    "    print(f\"Updating database with {total} translations in batches of {batch_size}...\")\n",
    "    \n",
    "    # Convert to list for batching\n",
    "    items = list(valid_translations.items())\n",
    "    updated_count = 0\n",
    "    conn = None\n",
    "    \n",
    "    try:\n",
    "        for i in range(0, len(items), batch_size):\n",
    "            batch = items[i:i + batch_size]\n",
    "            \n",
    "            # Create new connection for each batch\n",
    "            if conn:\n",
    "                try:\n",
    "                    conn.close()\n",
    "                except:\n",
    "                    pass\n",
    "            \n",
    "            conn = get_connection()\n",
    "            cursor = conn.cursor()\n",
    "            \n",
    "            # Update each item individually within transaction\n",
    "            for original, translated in batch:\n",
    "                try:\n",
    "                    update_query = \"\"\"\n",
    "                    UPDATE {} \n",
    "                    SET geolocation_city_en = %s \n",
    "                    WHERE geolocation_city = %s \n",
    "                    AND (geolocation_city_en IS NULL OR geolocation_city_en = '')\n",
    "                    \"\"\".format(table_name)\n",
    "                    \n",
    "                    cursor.execute(update_query, (translated, original))\n",
    "                    updated_count += 1\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"Error updating '{original}': {e}\")\n",
    "                    continue\n",
    "            \n",
    "            # Commit batch\n",
    "            conn.commit()\n",
    "            cursor.close()\n",
    "            \n",
    "            # Progress update\n",
    "            progress = ((i + len(batch)) * 100) // total\n",
    "            print(f\"Database update progress: {updated_count}/{total} ({progress}%)\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Database update error: {e}\")\n",
    "    finally:\n",
    "        if conn:\n",
    "            try:\n",
    "                conn.close()\n",
    "            except:\n",
    "                pass\n",
    "    \n",
    "    print(f\"‚úì Successfully updated {updated_count} records\")\n",
    "\n",
    "def main():\n",
    "    try:\n",
    "        start_time = time.time()\n",
    "        \n",
    "        print(\"=\" * 70)\n",
    "        print(\"Azure SQL Geolocation Translation Tool - Azure Translator API\")\n",
    "        print(\"=\" * 70)\n",
    "        \n",
    "        # Check configuration\n",
    "        if AZURE_TRANSLATOR_KEY == 'your_translator_key_here':\n",
    "            print(\"‚ùå ERROR: Please update AZURE_TRANSLATOR_KEY\")\n",
    "            print(\"\\nGet your key from:\")\n",
    "            print(\"Azure Portal ‚Üí Translator Resource ‚Üí Keys and Endpoint ‚Üí Key 1\")\n",
    "            return\n",
    "        \n",
    "        # Display current IP for troubleshooting\n",
    "        print(\"\\nüìç Getting your current IP address...\")\n",
    "        try:\n",
    "            import requests\n",
    "            current_ip = requests.get('https://api.ipify.org', timeout=5).text\n",
    "            print(f\"‚úì Your current IP: {current_ip}\")\n",
    "            print(\"  (Use this IP if you need to add a firewall rule)\")\n",
    "        except:\n",
    "            print(\"  (Could not detect IP)\")\n",
    "        \n",
    "        print(\"\\nüîå Connecting to Azure SQL Server...\")\n",
    "        print(f\"   Server: {SERVER}\")\n",
    "        print(f\"   Database: {DATABASE}\")\n",
    "        \n",
    "        conn = get_connection()\n",
    "        cursor = conn.cursor()\n",
    "        print(\"‚úì Connected successfully!\")\n",
    "        \n",
    "        # Check/create translation column\n",
    "        print(\"\\nüìã Checking table structure...\")\n",
    "        check_column_query = f\"\"\"\n",
    "        IF NOT EXISTS (\n",
    "            SELECT * FROM INFORMATION_SCHEMA.COLUMNS \n",
    "            WHERE TABLE_NAME = '{TABLE_NAME}' \n",
    "            AND COLUMN_NAME = 'geolocation_city_en'\n",
    "        )\n",
    "        BEGIN\n",
    "            ALTER TABLE {TABLE_NAME}\n",
    "            ADD geolocation_city_en NVARCHAR(255)\n",
    "        END\n",
    "        \"\"\"\n",
    "        cursor.execute(check_column_query)\n",
    "        conn.commit()\n",
    "        print(\"‚úì Table structure verified\")\n",
    "        \n",
    "        # Read untranslated unique cities\n",
    "        print(f\"\\nüìñ Reading untranslated cities from {TABLE_NAME}...\")\n",
    "        query = f\"\"\"\n",
    "        SELECT DISTINCT geolocation_city \n",
    "        FROM {TABLE_NAME} \n",
    "        WHERE (geolocation_city_en IS NULL OR geolocation_city_en = '')\n",
    "        AND geolocation_city IS NOT NULL\n",
    "        AND geolocation_city != ''\n",
    "        \"\"\"\n",
    "        df = pd.read_sql(query, conn)\n",
    "        \n",
    "        cursor.close()\n",
    "        conn.close()\n",
    "        \n",
    "        total_unique = len(df)\n",
    "        print(f\"‚úì Found {total_unique:,} unique cities to translate\")\n",
    "        \n",
    "        if total_unique == 0:\n",
    "            print(\"\\n‚úÖ All cities are already translated!\")\n",
    "            return\n",
    "        \n",
    "        # Get list of unique cities\n",
    "        unique_cities = df['geolocation_city'].tolist()\n",
    "        \n",
    "        # Estimate characters\n",
    "        total_chars = sum(len(str(city)) for city in unique_cities)\n",
    "        print(f\"\\nüìä Estimated characters: {total_chars:,}\")\n",
    "        print(f\"   Azure Free Tier: 2,000,000/month\")\n",
    "        print(f\"   Percentage: {(total_chars/2000000)*100:.2f}%\")\n",
    "        \n",
    "        if total_chars > 2000000:\n",
    "            print(\"   ‚ö†Ô∏è  WARNING: May exceed free tier limit\")\n",
    "        \n",
    "        # Translate all unique cities\n",
    "        print(f\"\\nüåê Starting translation...\")\n",
    "        print(f\"   Batch size: {BATCH_SIZE} cities/request\")\n",
    "        print(f\"   Parallel workers: {MAX_WORKERS}\")\n",
    "        \n",
    "        translations = translate_all_cities(unique_cities, BATCH_SIZE, MAX_WORKERS)\n",
    "        \n",
    "        # Update database in small batches\n",
    "        print(f\"\\nüíæ Updating database...\")\n",
    "        print(f\"   Update batch size: {DB_UPDATE_BATCH_SIZE} cities\")\n",
    "        \n",
    "        update_database_small_batches(translations, TABLE_NAME, DB_UPDATE_BATCH_SIZE)\n",
    "        \n",
    "        # Show sample results\n",
    "        print(\"\\nüìã Sample translations:\")\n",
    "        conn = get_connection()\n",
    "        sample_query = f\"\"\"\n",
    "        SELECT TOP 10 geolocation_city, geolocation_city_en \n",
    "        FROM {TABLE_NAME} \n",
    "        WHERE geolocation_city_en IS NOT NULL\n",
    "        ORDER BY geolocation_city\n",
    "        \"\"\"\n",
    "        sample_df = pd.read_sql(sample_query, conn)\n",
    "        print(sample_df.to_string(index=False))\n",
    "        conn.close()\n",
    "        \n",
    "        # Show statistics\n",
    "        elapsed_time = time.time() - start_time\n",
    "        print(f\"\\n\" + \"=\" * 70)\n",
    "        print(f\"‚úÖ TRANSLATION COMPLETED SUCCESSFULLY!\")\n",
    "        print(\"=\" * 70)\n",
    "        print(f\"üìä Statistics:\")\n",
    "        print(f\"   Unique cities translated: {total_unique:,}\")\n",
    "        print(f\"   Characters processed: {total_chars:,}\")\n",
    "        print(f\"   Time taken: {elapsed_time:.2f} seconds ({elapsed_time/60:.2f} minutes)\")\n",
    "        if elapsed_time > 0:\n",
    "            print(f\"   Average speed: {total_unique/elapsed_time:.2f} cities/second\")\n",
    "        print(\"=\" * 70)\n",
    "        \n",
    "    except pymssql.OperationalError as e:\n",
    "        error_code = e.args[0] if e.args else None\n",
    "        if error_code == 40615:\n",
    "            print(\"\\n‚ùå FIREWALL ERROR - Cannot connect to database\")\n",
    "            print(\"\\nPlease follow the instructions above to fix the firewall.\")\n",
    "        else:\n",
    "            print(f\"\\n‚ùå Database Error: {e}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "    except Exception as e:\n",
    "        print(f\"\\n‚ùå Error: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3ebfc7d2-b94c-4836-afe3-abcca2d81900",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (914646726.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[16], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    pip install pip\u001b[0m\n\u001b[1;37m        ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "173dfc52-3a27-4572-8989-6269dc827cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pymssql\n",
    "import requests\n",
    "import uuid\n",
    "import time\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "# Azure SQL Server Configuration\n",
    "SERVER = 'almagraby.database.windows.net'\n",
    "DATABASE = 'Olist_dataset'\n",
    "USERNAME = 'DEPI_Projecte'\n",
    "PASSWORD = 'Almaghraby@240'\n",
    "TABLE_NAME = 'olist_geolocation_dataset_olist_geolocation_dataset'  # Table containing geolocation_city column\n",
    "\n",
    "# Azure Translator Configuration\n",
    "AZURE_TRANSLATOR_KEY = 'AunHlUi5xLkxOBfcQnwIYmiLxh2PztKTD5b5Kbfu4uiLHt1alQKdJQQJ99BJACF24PCXJ3w3AAAbACOGZEWL'  # From Azure Portal\n",
    "AZURE_TRANSLATOR_REGION = 'uaenorth'  # Your translator region (e.g., eastus, westeurope)\n",
    "AZURE_TRANSLATOR_ENDPOINT = 'https://almagraby.cognitiveservices.azure.com/'\n",
    "\n",
    "# Performance Settings\n",
    "BATCH_SIZE = 100\n",
    "MAX_WORKERS = 5\n",
    "DB_UPDATE_BATCH_SIZE = 50  # CRITICAL: Smaller batches for UPDATE statements\n",
    "\n",
    "def get_connection():\n",
    "    \"\"\"Create a new database connection with retry logic\"\"\"\n",
    "    max_retries = 3\n",
    "    retry_delay = 5\n",
    "    \n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            conn = pymssql.connect(\n",
    "                server=SERVER,\n",
    "                user=USERNAME,\n",
    "                password=PASSWORD,\n",
    "                database=DATABASE,\n",
    "                port=1433,\n",
    "                tds_version='7.4',\n",
    "                timeout=60,\n",
    "                login_timeout=60\n",
    "            )\n",
    "            return conn\n",
    "        except pymssql.OperationalError as e:\n",
    "            error_code = e.args[0] if e.args else None\n",
    "            \n",
    "            if error_code == 40615:\n",
    "                # Firewall blocking\n",
    "                print(f\"\\n‚ö†Ô∏è  FIREWALL ERROR (Attempt {attempt + 1}/{max_retries})\")\n",
    "                print(\"=\" * 70)\n",
    "                print(\"Your Azure SQL Server firewall is blocking this connection.\")\n",
    "                print(\"\\nTO FIX THIS:\")\n",
    "                print(\"1. Get your current IP:\")\n",
    "                \n",
    "                try:\n",
    "                    import requests\n",
    "                    current_ip = requests.get('https://api.ipify.org', timeout=5).text\n",
    "                    print(f\"   Your IP: {current_ip}\")\n",
    "                except:\n",
    "                    print(\"   Run: import requests; print(requests.get('https://api.ipify.org').text)\")\n",
    "                \n",
    "                print(\"\\n2. Add to Azure Firewall:\")\n",
    "                print(\"   ‚Ä¢ Azure Portal ‚Üí SQL Server ‚Üí Networking\")\n",
    "                print(\"   ‚Ä¢ Click '+ Add firewall rule'\")\n",
    "                print(f\"   ‚Ä¢ Start IP: {current_ip if 'current_ip' in locals() else '<your_ip>'}\")\n",
    "                print(f\"   ‚Ä¢ End IP: {current_ip if 'current_ip' in locals() else '<your_ip>'}\")\n",
    "                print(\"   ‚Ä¢ Click 'Save' and wait 2-5 minutes\")\n",
    "                print(\"\\n3. OR Enable 'Allow Azure services' (Recommended):\")\n",
    "                print(\"   ‚Ä¢ Azure Portal ‚Üí SQL Server ‚Üí Networking\")\n",
    "                print(\"   ‚Ä¢ Toggle ON: 'Allow Azure services and resources to access this server'\")\n",
    "                print(\"   ‚Ä¢ Click 'Save'\")\n",
    "                print(\"=\" * 70)\n",
    "                \n",
    "                if attempt < max_retries - 1:\n",
    "                    print(f\"\\nWaiting {retry_delay} seconds before retry...\")\n",
    "                    time.sleep(retry_delay)\n",
    "                else:\n",
    "                    print(\"\\n‚ùå Max retries reached. Please fix firewall and re-run.\")\n",
    "                    raise\n",
    "            else:\n",
    "                # Other connection errors\n",
    "                print(f\"\\n‚ùå Connection Error: {e}\")\n",
    "                if attempt < max_retries - 1:\n",
    "                    print(f\"Retrying in {retry_delay} seconds...\")\n",
    "                    time.sleep(retry_delay)\n",
    "                else:\n",
    "                    raise\n",
    "        except Exception as e:\n",
    "            print(f\"\\n‚ùå Unexpected Error: {e}\")\n",
    "            if attempt < max_retries - 1:\n",
    "                print(f\"Retrying in {retry_delay} seconds...\")\n",
    "                time.sleep(retry_delay)\n",
    "            else:\n",
    "                raise\n",
    "    \n",
    "    raise Exception(\"Failed to connect after all retries\")\n",
    "\n",
    "def translate_batch_azure(cities):\n",
    "    \"\"\"Translate a batch of cities using Azure Translator API\"\"\"\n",
    "    if not cities:\n",
    "        return {}\n",
    "    \n",
    "    valid_cities = [city for city in cities if pd.notna(city) and city != '']\n",
    "    \n",
    "    if not valid_cities:\n",
    "        return {city: city for city in cities}\n",
    "    \n",
    "    path = '/translate'\n",
    "    constructed_url = AZURE_TRANSLATOR_ENDPOINT + path\n",
    "    \n",
    "    params = {\n",
    "        'api-version': '3.0',\n",
    "        'from': 'auto',\n",
    "        'to': 'en'\n",
    "    }\n",
    "    \n",
    "    headers = {\n",
    "        'Ocp-Apim-Subscription-Key': AZURE_TRANSLATOR_KEY,\n",
    "        'Ocp-Apim-Subscription-Region': AZURE_TRANSLATOR_REGION,\n",
    "        'Content-type': 'application/json',\n",
    "        'X-ClientTraceId': str(uuid.uuid4())\n",
    "    }\n",
    "    \n",
    "    body = [{'text': str(city)} for city in valid_cities]\n",
    "    translations = {}\n",
    "    \n",
    "    try:\n",
    "        response = requests.post(constructed_url, params=params, headers=headers, json=body)\n",
    "        response.raise_for_status()\n",
    "        results = response.json()\n",
    "        \n",
    "        for city, result in zip(valid_cities, results):\n",
    "            translated_text = result['translations'][0]['text']\n",
    "            translations[city] = translated_text\n",
    "        \n",
    "        for city in cities:\n",
    "            if pd.isna(city) or city == '':\n",
    "                translations[city] = city\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Translation error: {e}\")\n",
    "        translations = {city: city for city in cities}\n",
    "    \n",
    "    return translations\n",
    "\n",
    "def translate_all_cities(unique_cities, batch_size=BATCH_SIZE, max_workers=MAX_WORKERS):\n",
    "    \"\"\"Translate all unique cities using Azure Translator with parallel processing\"\"\"\n",
    "    print(f\"Translating {len(unique_cities)} unique cities...\")\n",
    "    \n",
    "    city_batches = [unique_cities[i:i + batch_size] \n",
    "                    for i in range(0, len(unique_cities), batch_size)]\n",
    "    \n",
    "    all_translations = {}\n",
    "    completed = 0\n",
    "    \n",
    "    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        future_to_batch = {executor.submit(translate_batch_azure, batch): batch \n",
    "                          for batch in city_batches}\n",
    "        \n",
    "        for future in as_completed(future_to_batch):\n",
    "            try:\n",
    "                translations = future.result()\n",
    "                all_translations.update(translations)\n",
    "                completed += len(translations)\n",
    "                progress = (completed * 100) // len(unique_cities)\n",
    "                print(f\"Progress: {completed}/{len(unique_cities)} cities ({progress}%)\")\n",
    "            except Exception as e:\n",
    "                print(f\"Batch processing error: {e}\")\n",
    "    \n",
    "    return all_translations\n",
    "\n",
    "def update_database_small_batches(translations, table_name, batch_size=DB_UPDATE_BATCH_SIZE):\n",
    "    \"\"\"\n",
    "    Update database in SMALL batches to avoid query size limits\n",
    "    Uses individual UPDATE statements, not CASE\n",
    "    \"\"\"\n",
    "    if not translations:\n",
    "        return\n",
    "    \n",
    "    valid_translations = {k: v for k, v in translations.items() \n",
    "                         if k and v and pd.notna(k) and pd.notna(v)}\n",
    "    \n",
    "    if not valid_translations:\n",
    "        print(\"No valid translations to update\")\n",
    "        return\n",
    "    \n",
    "    total = len(valid_translations)\n",
    "    print(f\"Updating database with {total} translations in batches of {batch_size}...\")\n",
    "    \n",
    "    # Convert to list for batching\n",
    "    items = list(valid_translations.items())\n",
    "    updated_count = 0\n",
    "    conn = None\n",
    "    \n",
    "    try:\n",
    "        for i in range(0, len(items), batch_size):\n",
    "            batch = items[i:i + batch_size]\n",
    "            \n",
    "            # Create new connection for each batch\n",
    "            if conn:\n",
    "                try:\n",
    "                    conn.close()\n",
    "                except:\n",
    "                    pass\n",
    "            \n",
    "            conn = get_connection()\n",
    "            cursor = conn.cursor()\n",
    "            \n",
    "            # Update each item individually within transaction\n",
    "            for original, translated in batch:\n",
    "                try:\n",
    "                    update_query = \"\"\"\n",
    "                    UPDATE {} \n",
    "                    SET geolocation_city_en = %s \n",
    "                    WHERE geolocation_city = %s \n",
    "                    AND (geolocation_city_en IS NULL OR geolocation_city_en = '')\n",
    "                    \"\"\".format(table_name)\n",
    "                    \n",
    "                    cursor.execute(update_query, (translated, original))\n",
    "                    updated_count += 1\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"Error updating '{original}': {e}\")\n",
    "                    continue\n",
    "            \n",
    "            # Commit batch\n",
    "            conn.commit()\n",
    "            cursor.close()\n",
    "            \n",
    "            # Progress update\n",
    "            progress = ((i + len(batch)) * 100) // total\n",
    "            print(f\"Database update progress: {updated_count}/{total} ({progress}%)\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Database update error: {e}\")\n",
    "    finally:\n",
    "        if conn:\n",
    "            try:\n",
    "                conn.close()\n",
    "            except:\n",
    "                pass\n",
    "    \n",
    "    print(f\"‚úì Successfully updated {updated_count} records\")\n",
    "\n",
    "def main():\n",
    "    try:\n",
    "        start_time = time.time()\n",
    "        \n",
    "        print(\"=\" * 70)\n",
    "        print(\"Azure SQL Geolocation Translation Tool - Azure Translator API\")\n",
    "        print(\"=\" * 70)\n",
    "        \n",
    "        # Check configuration\n",
    "        if AZURE_TRANSLATOR_KEY == 'your_translator_key_here':\n",
    "            print(\"‚ùå ERROR: Please update AZURE_TRANSLATOR_KEY\")\n",
    "            print(\"\\nGet your key from:\")\n",
    "            print(\"Azure Portal ‚Üí Translator Resource ‚Üí Keys and Endpoint ‚Üí Key 1\")\n",
    "            return\n",
    "        \n",
    "        # Display current IP for troubleshooting\n",
    "        print(\"\\nüìç Getting your current IP address...\")\n",
    "        try:\n",
    "            import requests\n",
    "            current_ip = requests.get('https://api.ipify.org', timeout=5).text\n",
    "            print(f\"‚úì Your current IP: {current_ip}\")\n",
    "            print(\"  (Use this IP if you need to add a firewall rule)\")\n",
    "        except:\n",
    "            print(\"  (Could not detect IP)\")\n",
    "        \n",
    "        print(\"\\nüîå Connecting to Azure SQL Server...\")\n",
    "        print(f\"   Server: {SERVER}\")\n",
    "        print(f\"   Database: {DATABASE}\")\n",
    "        \n",
    "        conn = get_connection()\n",
    "        cursor = conn.cursor()\n",
    "        print(\"‚úì Connected successfully!\")\n",
    "        \n",
    "        # Check/create translation column\n",
    "        print(\"\\nüìã Checking table structure...\")\n",
    "        check_column_query = f\"\"\"\n",
    "        IF NOT EXISTS (\n",
    "            SELECT * FROM INFORMATION_SCHEMA.COLUMNS \n",
    "            WHERE TABLE_NAME = '{TABLE_NAME}' \n",
    "            AND COLUMN_NAME = 'geolocation_city_en'\n",
    "        )\n",
    "        BEGIN\n",
    "            ALTER TABLE {TABLE_NAME}\n",
    "            ADD geolocation_city_en NVARCHAR(255)\n",
    "        END\n",
    "        \"\"\"\n",
    "        cursor.execute(check_column_query)\n",
    "        conn.commit()\n",
    "        print(\"‚úì Table structure verified\")\n",
    "        \n",
    "        # Read untranslated unique cities\n",
    "        print(f\"\\nüìñ Reading untranslated cities from {TABLE_NAME}...\")\n",
    "        query = f\"\"\"\n",
    "        SELECT DISTINCT geolocation_city \n",
    "        FROM {TABLE_NAME} \n",
    "        WHERE (geolocation_city_en IS NULL OR geolocation_city_en = '')\n",
    "        AND geolocation_city IS NOT NULL\n",
    "        AND geolocation_city != ''\n",
    "        \"\"\"\n",
    "        df = pd.read_sql(query, conn)\n",
    "        \n",
    "        cursor.close()\n",
    "        conn.close()\n",
    "        \n",
    "        total_unique = len(df)\n",
    "        print(f\"‚úì Found {total_unique:,} unique cities to translate\")\n",
    "        \n",
    "        if total_unique == 0:\n",
    "            print(\"\\n‚úÖ All cities are already translated!\")\n",
    "            return\n",
    "        \n",
    "        # Get list of unique cities\n",
    "        unique_cities = df['geolocation_city'].tolist()\n",
    "        \n",
    "        # Estimate characters\n",
    "        total_chars = sum(len(str(city)) for city in unique_cities)\n",
    "        print(f\"\\nüìä Estimated characters: {total_chars:,}\")\n",
    "        print(f\"   Azure Free Tier: 2,000,000/month\")\n",
    "        print(f\"   Percentage: {(total_chars/2000000)*100:.2f}%\")\n",
    "        \n",
    "        if total_chars > 2000000:\n",
    "            print(\"   ‚ö†Ô∏è  WARNING: May exceed free tier limit\")\n",
    "        \n",
    "        # Translate all unique cities\n",
    "        print(f\"\\nüåê Starting translation...\")\n",
    "        print(f\"   Batch size: {BATCH_SIZE} cities/request\")\n",
    "        print(f\"   Parallel workers: {MAX_WORKERS}\")\n",
    "        \n",
    "        translations = translate_all_cities(unique_cities, BATCH_SIZE, MAX_WORKERS)\n",
    "        \n",
    "        # Update database in small batches\n",
    "        print(f\"\\nüíæ Updating database...\")\n",
    "        print(f\"   Update batch size: {DB_UPDATE_BATCH_SIZE} cities\")\n",
    "        \n",
    "        update_database_small_batches(translations, TABLE_NAME, DB_UPDATE_BATCH_SIZE)\n",
    "        \n",
    "        # Show sample results\n",
    "        print(\"\\nüìã Sample translations:\")\n",
    "        conn = get_connection()\n",
    "        sample_query = f\"\"\"\n",
    "        SELECT TOP 10 geolocation_city, geolocation_city_en \n",
    "        FROM {TABLE_NAME} \n",
    "        WHERE geolocation_city_en IS NOT NULL\n",
    "        ORDER BY geolocation_city\n",
    "        \"\"\"\n",
    "        sample_df = pd.read_sql(sample_query, conn)\n",
    "        print(sample_df.to_string(index=False))\n",
    "        conn.close()\n",
    "        \n",
    "        # Show statistics\n",
    "        elapsed_time = time.time() - start_time\n",
    "        print(f\"\\n\" + \"=\" * 70)\n",
    "        print(f\"‚úÖ TRANSLATION COMPLETED SUCCESSFULLY!\")\n",
    "        print(\"=\" * 70)\n",
    "        print(f\"üìä Statistics:\")\n",
    "        print(f\"   Unique cities translated: {total_unique:,}\")\n",
    "        print(f\"   Characters processed: {total_chars:,}\")\n",
    "        print(f\"   Time taken: {elapsed_time:.2f} seconds ({elapsed_time/60:.2f} minutes)\")\n",
    "        if elapsed_time > 0:\n",
    "            print(f\"   Average speed: {total_unique/elapsed_time:.2f} cities/second\")\n",
    "        print(\"=\" * 70)\n",
    "        \n",
    "    except pymssql.OperationalError as e:\n",
    "        error_code = e.args[0] if e.args else None\n",
    "        if error_code == 40615:\n",
    "            print(\"\\n‚ùå FIREWALL ERROR - Cannot connect to database\")\n",
    "            print(\"\\nPlease follow the instructions above to fix the firewall.\")\n",
    "        else:\n",
    "            print(f\"\\n‚ùå Database Error: {e}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "    except Exception as e:\n",
    "        print(f\"\\n‚ùå Error: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
